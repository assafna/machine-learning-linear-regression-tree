{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_learning_linear_regression_tree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP98UURgc28wwZSzPmYSJy/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assafna/machine-learning-linear-regression-tree/blob/main/machine_learning_linear_regression_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AsiSW1k5lzA"
      },
      "source": [
        "The goal of this task is to create a linear regression tree that can predict a numerical value for a new sample based on linear regression models in the leaves.\r\n",
        "\r\n",
        "The following will occur:\r\n",
        "\r\n",
        "\r\n",
        "*   Each node in the tree will have a linear regression model and a MSE score.\r\n",
        "*   Each split will be made based on the feature that gives the lowest MSE score. This feature's MSE score will be the lowest MSE score out of all possible splits of the feature values.\r\n",
        "*   The MSE score will be normalized by the number of instances.\r\n",
        "*   Split values will be the mean of each two (unique) consecutive samples.\r\n",
        "*   All features will be considered in every depth.\r\n",
        "*   Nominal features will be split to all values.\r\n",
        "*   The tree will recieve a minimal samples to split parameter.\r\n",
        "*   The regression algorithm will be chosen by the user.\r\n",
        "*   The tree will be created from top to bottom.\r\n",
        "*   No pruning will be made.\r\n",
        "*   There are no missing values.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIP3FX76SAiF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGn3jLMC4YfC"
      },
      "source": [
        "id = 0\r\n",
        "\r\n",
        "class Node:\r\n",
        "  def __init__(self, parent_node_id, parent_depth, df, split_node, linear_regression_model, columns, mse_score):\r\n",
        "    global id\r\n",
        "    self.id = id\r\n",
        "    id += 1\r\n",
        "    self.depth = parent_depth + 1\r\n",
        "    self.linear_regression_model = linear_regression_model\r\n",
        "    self.mse_score = mse_score\r\n",
        "    self.columns = columns\r\n",
        "\r\n",
        "    results = split_node(df, self.depth)\r\n",
        "\r\n",
        "    # no split\r\n",
        "    if results is None:\r\n",
        "      self.is_leaf = True\r\n",
        "      print('Created node #' + str(self.id), ' (leaf), child of node #' + str(parent_node_id))\r\n",
        "      return\r\n",
        "\r\n",
        "    # split\r\n",
        "    best_split_feature, best_split_value, best_split_models, best_split_models_columns, best_split_mse_scores = results\r\n",
        "    self.is_leaf = False\r\n",
        "    self.split_feature = best_split_feature\r\n",
        "\r\n",
        "    print('Created node #' + str(self.id), ' (' + str(self.split_feature) + ' - ' + str(best_split_value) + '), child of node #' + str(parent_node_id))\r\n",
        "\r\n",
        "    # categorical or numeric\r\n",
        "    if isinstance(best_split_value, list):\r\n",
        "      self.is_numeric = False\r\n",
        "      self.children = {child_value: Node(self.id, self.depth, df[df[self.split_feature] == child_value], split_node, child_model, child_model_columns, child_mse_score) for \r\n",
        "                       child_value, child_model, child_model_columns, child_mse_score in zip(best_split_value, best_split_models, best_split_models_columns, best_split_mse_scores)}\r\n",
        "    else:\r\n",
        "      self.is_numeric = True\r\n",
        "      self.split_value = best_split_value\r\n",
        "      self.children = [\r\n",
        "        Node(self.id, self.depth, df[df[self.split_feature] < self.split_value], split_node, best_split_models[0], best_split_models_columns[0], best_split_mse_scores[0]),\r\n",
        "        Node(self.id, self.depth, df[df[self.split_feature] > self.split_value], split_node, best_split_models[1], best_split_models_columns[1], best_split_mse_scores[1])\r\n",
        "      ]\r\n",
        "\r\n",
        "  def predict(self, X):\r\n",
        "    # a leaf\r\n",
        "    if self.is_leaf:\r\n",
        "      X_dummies = pd.get_dummies(X)\r\n",
        "      return list(self.linear_regression_model.predict(X_dummies))\r\n",
        "\r\n",
        "    # numeric\r\n",
        "    if self.is_numeric:\r\n",
        "      lower_values = X[X[self.split_feature] < self.split_value]\r\n",
        "      greater_values = X[X[self.split_feature] > self.split_value]\r\n",
        "      return self.children[0].predict(lower_values) + self.children[1].predict(greater_values)\r\n",
        "\r\n",
        "    # categorial\r\n",
        "    y_pred = []\r\n",
        "    for value in X[self.split_feature].unique():\r\n",
        "      equal_values = X[X[self.split_feature] == value]\r\n",
        "      y_pred += self.children[value].predict(equal_values)\r\n",
        "\r\n",
        "    return y_pred"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fja3mszE7dM"
      },
      "source": [
        "class LinearRegressionTree:\r\n",
        "  def __init__(self, linear_regression_model, min_samples_for_split, max_depth, target_variable):\r\n",
        "    self.linear_regression_model = linear_regression_model\r\n",
        "    self.min_samples_for_split = min_samples_for_split\r\n",
        "    self.max_depth = max_depth\r\n",
        "    self.target_variable = target_variable\r\n",
        "    self.root = None\r\n",
        "\r\n",
        "  def split_to_X_and_y(self, df):\r\n",
        "    X = df.drop(columns=[self.target_variable])\r\n",
        "    y = df[self.target_variable]\r\n",
        "\r\n",
        "    return X, y\r\n",
        "\r\n",
        "  def linear_model_fit_and_predict(self, df):\r\n",
        "    X, y = self.split_to_X_and_y(df)\r\n",
        "    \r\n",
        "    # categorical features to numerical\r\n",
        "    X = pd.get_dummies(X)\r\n",
        "\r\n",
        "    model = self.linear_regression_model().fit(X, y)\r\n",
        "    y_pred = model.predict(X)\r\n",
        "\r\n",
        "    return model, list(X.columns), y, y_pred\r\n",
        "\r\n",
        "  def compute_mse_score(self, y_true, y_pred):\r\n",
        "    return mean_squared_error(y_true, y_pred) / len(y_true)\r\n",
        "\r\n",
        "  def fit(self, df):\r\n",
        "    model, model_columns, y_true, y_pred = self.linear_model_fit_and_predict(df)\r\n",
        "    mse_score = self.compute_mse_score(y_true, y_pred)\r\n",
        "    self.root = Node(None, 0, df, self.split_node, model, model_columns, mse_score)\r\n",
        "\r\n",
        "  def numeric_feature_best_mse_score(self, df, feature):\r\n",
        "    best_weighted_mse_score = float('inf')\r\n",
        "    best_split_value = None\r\n",
        "    best_split_models = []\r\n",
        "    best_split_models_columns = []\r\n",
        "    best_split_mse_scores = []\r\n",
        "\r\n",
        "    feature_values = df[feature]\r\n",
        "    feature_unique_values = np.sort(feature_values.unique())\r\n",
        "    for value_index in range(len(feature_unique_values) - 1):\r\n",
        "      value = (feature_unique_values[value_index] + \r\n",
        "              feature_unique_values[value_index + 1]) / 2\r\n",
        "\r\n",
        "      lower_values = df[feature_values.lt(value)]\r\n",
        "      greater_values = df[feature_values.gt(value)]\r\n",
        "\r\n",
        "      lower_model, lower_model_columns, lower_model_y_true, lower_model_y_pred = self.linear_model_fit_and_predict(lower_values)\r\n",
        "      greater_model, greater_model_columns, greater_model_y_true, greater_model_y_pred = self.linear_model_fit_and_predict(greater_values)\r\n",
        "\r\n",
        "      lower_mse = self.compute_mse_score(lower_model_y_true, lower_model_y_pred)\r\n",
        "      greater_mse = self.compute_mse_score(greater_model_y_true, greater_model_y_pred)\r\n",
        "\r\n",
        "      weighted_mse_score = (lower_mse + greater_mse) / 2\r\n",
        "      if weighted_mse_score < best_weighted_mse_score:\r\n",
        "        best_weighted_mse_score = weighted_mse_score\r\n",
        "        best_split_value = value\r\n",
        "        best_split_models = [lower_model, greater_model]\r\n",
        "        best_split_models_columns = [lower_model_columns, greater_model_columns]\r\n",
        "        best_split_mse_scores = [lower_mse, greater_mse]\r\n",
        "    \r\n",
        "    return best_weighted_mse_score, best_split_value, best_split_models, best_split_models_columns, best_split_mse_scores\r\n",
        "\r\n",
        "  def categorical_feature_mse_score(self, df, feature):\r\n",
        "    models = []\r\n",
        "    models_columns = []\r\n",
        "    mse_scores = []\r\n",
        "\r\n",
        "    feature_values = df[feature]\r\n",
        "    feature_unique_values = feature_values.unique()\r\n",
        "    for value in feature_unique_values:\r\n",
        "      equal_values = df[feature_values.eq(value)]\r\n",
        "      model, model_columns, y_true, y_pred = self.linear_model_fit_and_predict(equal_values)\r\n",
        "      models.append(model)\r\n",
        "      models_columns.append(model_columns)\r\n",
        "      mse_score = self.compute_mse_score(y_true, y_pred)\r\n",
        "      mse_scores.append(mse_score)\r\n",
        "\r\n",
        "    weighted_mse_score = np.mean(mse_scores)\r\n",
        "    return weighted_mse_score, list(feature_unique_values), models, models_columns, mse_scores\r\n",
        "\r\n",
        "  def is_feature_numeric(self, df, feature):\r\n",
        "    return df.dtypes[feature] == 'int64' or df.dtypes[feature] == 'float64'\r\n",
        "\r\n",
        "  def features_best_mse_score(self, df):\r\n",
        "    best_weighted_mse_score = float('inf')\r\n",
        "    best_split_feature = None\r\n",
        "    best_split_value = None\r\n",
        "    best_split_models = None\r\n",
        "    best_split_models_columns = None\r\n",
        "    best_split_mse_scores = None\r\n",
        "\r\n",
        "    features = list(df.columns)\r\n",
        "    features.remove(self.target_variable)\r\n",
        "    for feature in features:\r\n",
        "      if self.is_feature_numeric(df, feature):\r\n",
        "        weighted_mse_score, split_value, models, models_columns, mse_scores = self.numeric_feature_best_mse_score(df, feature)\r\n",
        "      else:\r\n",
        "        weighted_mse_score, split_value, models, models_columns, mse_scores = self.categorical_feature_mse_score(df, feature)\r\n",
        "      \r\n",
        "      if weighted_mse_score < best_weighted_mse_score:\r\n",
        "        best_weighted_mse_score = weighted_mse_score\r\n",
        "        best_split_feature = feature\r\n",
        "        best_split_value = split_value\r\n",
        "        best_split_models = models\r\n",
        "        best_split_models_columns = models_columns\r\n",
        "        best_split_mse_scores = mse_scores\r\n",
        "    \r\n",
        "    return best_split_feature, best_split_value, best_split_models, best_split_models_columns, best_split_mse_scores\r\n",
        "\r\n",
        "  def split_node(self, df, depth):\r\n",
        "    if len(df) < self.min_samples_for_split or depth > self.max_depth:\r\n",
        "      return None\r\n",
        "\r\n",
        "    return self.features_best_mse_score(df)\r\n",
        "\r\n",
        "  def predict(self, X):\r\n",
        "    return self.root.predict(X)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQeuL01oa-ug",
        "outputId": "e3531f93-5487-477a-fa8a-371835d2fd2e"
      },
      "source": [
        "df = pd.read_csv('forestfires.csv')\r\n",
        "linear_regression_tree = LinearRegressionTree(\r\n",
        "    linear_regression_model=LinearRegression, \r\n",
        "    min_samples_for_split=5,\r\n",
        "    max_depth=4,\r\n",
        "    target_variable='area'\r\n",
        ")\r\n",
        "linear_regression_tree.fit(df)\r\n",
        "X = df.drop(columns=['area'])\r\n",
        "y = df['area']\r\n",
        "y_pred = linear_regression_tree.predict(X)\r\n",
        "mse_score = mean_squared_error(y, y_pred)\r\n",
        "print(mse_score)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created node #0  (DMC - 290.65), child of node #None\n",
            "Created node #1  (FFMC - 34.55), child of node #0\n",
            "Created node #2  (leaf), child of node #1\n",
            "Created node #3  (DMC - 2.7), child of node #1\n",
            "Created node #4  (leaf), child of node #3\n",
            "Created node #5  (temp - 3.2), child of node #3\n",
            "Created node #6  (leaf), child of node #5\n",
            "Created node #7  (leaf), child of node #5\n",
            "Created node #8  (leaf), child of node #0\n",
            "4042.1161388601436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2gOT2owpCHv"
      },
      "source": [
        "Let's compare it to a regular decision tree regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tu31Jbhmvb1",
        "outputId": "6f7cacf8-0c43-487d-a142-abfd10c8c64d"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\r\n",
        "\r\n",
        "df = pd.get_dummies(pd.read_csv('forestfires.csv'))\r\n",
        "X = df.drop(columns=['area'])\r\n",
        "y = df['area']\r\n",
        "dtr = DecisionTreeRegressor(min_samples_split=5, max_depth=4)\r\n",
        "dtr.fit(X, y)\r\n",
        "y_pred = dtr.predict(X)\r\n",
        "mse_score = mean_squared_error(y, y_pred)\r\n",
        "print(mse_score)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1059.882993558152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkPCPWNuqCHI"
      },
      "source": [
        "There's a lot to improve"
      ]
    }
  ]
}